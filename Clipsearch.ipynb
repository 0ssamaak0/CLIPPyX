{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "from CLIP.mobile_clip import get_clip_image, get_clip_text\n",
    "\n",
    "# from clip_transformers import get_clip_image, get_clip_text\n",
    "from OCR import apply_OCR\n",
    "\n",
    "from text_embeddings.embedding_llamacpp import get_text_embeddings\n",
    "\n",
    "# from text_HFtransformers import get_text_embeddings\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectordb(path):\n",
    "    \"\"\"\n",
    "    Create and return image and text collections in a VectorDB database.\n",
    "\n",
    "    This function initializes a PersistentClient with the given path, and then\n",
    "    gets or creates two collections: 'images' and 'texts'. Both collections\n",
    "    use cosine similarity for nearest neighbor search.\n",
    "\n",
    "    Args:\n",
    "        path (str): The path to the VectorDB database.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two Collection objects. The first element\n",
    "        is the 'images' collection, and the second element is the 'texts'\n",
    "        collection.\n",
    "    \"\"\"\n",
    "    client = chromadb.PersistentClient(\n",
    "        path,\n",
    "    )\n",
    "    image_collection = client.get_or_create_collection(\n",
    "        \"images\", metadata={\"hnsw:space\": \"cosine\"}\n",
    "    )\n",
    "    text_collection = client.get_or_create_collection(\n",
    "        \"texts\", metadata={\"hnsw:space\": \"cosine\"}\n",
    "    )\n",
    "    return image_collection, text_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_paths(file_path):\n",
    "    \"\"\"\n",
    "    Extract image paths from a file and return them in original and OS-specific formats.\n",
    "\n",
    "    This function reads a file line by line, with each line expected to contain a path to an image.\n",
    "    It returns two lists of paths: one with the original paths as they are in the file, and one with\n",
    "    the paths formatted for the current operating system.\n",
    "\n",
    "    If the script is running on a POSIX system (like Linux or WSL), it will replace backslashes with\n",
    "    forward slashes and 'C:' with '/mnt/c' in the paths.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the file containing the image paths.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two lists of strings. The first list contains the original paths,\n",
    "        and the second list contains the OS-specific paths.\n",
    "    \"\"\"\n",
    "    original_paths = []\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            original_paths.append(line.strip())\n",
    "\n",
    "    if os.name == \"posix\":  # If running on WSL\n",
    "        os_paths = [\n",
    "            path.replace(\"\\\\\", \"/\").replace(\"C:\", \"/mnt/c\") for path in original_paths\n",
    "        ]\n",
    "    else:\n",
    "        os_paths = original_paths\n",
    "    return original_paths, os_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing images:  19%|█▊        | 20/107 [00:08<00:26,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: not a PNG file in /mnt/c/Pneumothorax-segmentation/assets/fpn.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing images: 100%|██████████| 107/107 [00:43<00:00,  2.46it/s]\n",
      "Cleaning up database: 100%|██████████| 107/107 [00:00<00:00, 785972.90it/s]\n"
     ]
    }
   ],
   "source": [
    "def index_images(os_paths, original_paths, image_collection, text_collection):\n",
    "    \"\"\"\n",
    "    Index images in the database.\n",
    "\n",
    "    This function iterates over all image paths in the OS-specific format (os_paths), and for each path,\n",
    "    it checks if the image is already in the image collection using the original path. If not, it gets\n",
    "    the image embeddings and upserts them into the image collection. It also applies OCR to the image\n",
    "    and upserts the text embeddings into the text collection.\n",
    "\n",
    "    Args:\n",
    "        os_paths (list): The list of image paths in OS-specific format. These paths are used to read\n",
    "                         the images and apply OCR.\n",
    "        original_paths (list): The list of original image paths. These paths are used as IDs in the\n",
    "                               image and text collections.\n",
    "        image_collection (Collection): The image collection in the database.\n",
    "        text_collection (Collection): The text collection in the database.\n",
    "    \"\"\"\n",
    "    for i, image in tqdm(\n",
    "        enumerate(os_paths), total=len(os_paths), desc=\"Indexing images\"\n",
    "    ):\n",
    "        if len(image_collection.get(ids=original_paths[i])[\"ids\"]) > 0:\n",
    "            continue\n",
    "        image_embeddings = get_clip_image(os_paths[i])\n",
    "        image_collection.upsert(ids=[original_paths[i]], embeddings=image_embeddings)\n",
    "        ocr_text = apply_OCR(os_paths[i])\n",
    "        if ocr_text is not None:\n",
    "            text_embeddings = get_text_embeddings(ocr_text)\n",
    "            text_collection.upsert(ids=[original_paths[i]], embeddings=text_embeddings)\n",
    "\n",
    "\n",
    "def clean_index(original_paths, image_collection, text_collection):\n",
    "    \"\"\"\n",
    "    Clean up the database.\n",
    "\n",
    "    This function iterates over all IDs in the image collection, and for each ID, it checks if the ID is in\n",
    "    the list of original image paths. If not, it deletes the ID from the image collection and the text collection.\n",
    "\n",
    "    Args:\n",
    "        original_paths (list): The list of original image paths. These paths are used as IDs in the\n",
    "                               image and text collections.\n",
    "        image_collection (Collection): The image collection in the database.\n",
    "        text_collection (Collection): The text collection in the database.\n",
    "    \"\"\"\n",
    "    for i, id in tqdm(\n",
    "        enumerate(image_collection.get()[\"ids\"]),\n",
    "        total=len(image_collection.get()[\"ids\"]),\n",
    "        desc=\"Cleaning up database\",\n",
    "    ):\n",
    "        if id not in original_paths:\n",
    "            print(f\"deleting: {id} from image_collection\")\n",
    "            image_collection.delete(ids=[id])\n",
    "            try:\n",
    "                print(f\"deleting: {id} from text_collection\")\n",
    "                text_collection.delete(ids=[id])\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_image(text, image_collection):\n",
    "    text_embedding = get_clip_text(text)\n",
    "    results = image_collection.query(text_embedding, n_results=5)\n",
    "    distances = results[\"distances\"][0]\n",
    "    paths = results[\"ids\"][0]\n",
    "    return paths, distances\n",
    "\n",
    "\n",
    "def search_text(text, text_collection):\n",
    "    text_embedding = get_text_embeddings(text)\n",
    "    results = text_collection.query(text_embedding, n_results=5)\n",
    "    distances = results[\"distances\"][0]\n",
    "    paths = results[\"ids\"][0]\n",
    "    return paths, distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://172.25.97.13:5000\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "@app.route(\"/search\", methods=[\"POST\"])\n",
    "def search_route():\n",
    "    text = request.json.get(\"text\", \"\")\n",
    "    paths, distances = search_image(text)\n",
    "    print(distances)\n",
    "    return jsonify(paths)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host=\"0.0.0.0\", port=5000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
